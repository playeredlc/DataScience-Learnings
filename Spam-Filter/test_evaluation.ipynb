{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polish-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "falling-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 2500\n",
    "\n",
    "TOKEN_SPAM_PROB_FILE = 'spam-data/token-spam-prob.txt'\n",
    "TOKEN_HAM_PROB_FILE = 'spam-data/token-ham-prob.txt'\n",
    "TOKEN_OVERALL_PROB_FILE = 'spam-data/token-overall-prob.txt'\n",
    "\n",
    "TEST_FEATURE_MATRIX = 'spam-data/test-features.txt'\n",
    "TEST_TARGET_FILE = 'spam-data/test-target.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-produce",
   "metadata": {},
   "source": [
    "## *Load data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organized-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.loadtxt(TEST_FEATURE_MATRIX, delimiter=' ') # features\n",
    "y_test = np.loadtxt(TEST_TARGET_FILE, delimiter=' ') # target\n",
    "\n",
    "# probabilities\n",
    "prob_token_spam = np.loadtxt(TOKEN_SPAM_PROB_FILE, delimiter=' ')\n",
    "prob_token_ham = np.loadtxt(TOKEN_HAM_PROB_FILE, delimiter=' ')\n",
    "prob_token_overall = np.loadtxt(TOKEN_OVERALL_PROB_FILE, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-disney",
   "metadata": {},
   "source": [
    "---\n",
    "## *Bayes formula:*\n",
    "## $P(Spam \\, | \\, X) = \\frac{P(X \\, | \\, Spam) \\, P (Spam)}{P(X)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "matched-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.43156992,  -5.25657795,  -4.95782974, ..., -11.48212599,\n",
       "        -9.23083419, -11.07666089])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the prior (prior is a initial 'guess' based on prior knowledge)\n",
    "PRIOR_PROB_SPAM = 0.3116 # calculated in the training_model notebook\n",
    "# convert probabilities to log values (simplifies calculation (avoid multiplications and division) and spread the values for better visualizaton)\n",
    "np.log(prob_token_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-denmark",
   "metadata": {},
   "source": [
    "## *Joint probability (Spam and Ham)*\n",
    "### *using the dot product (multiply the whole X_test array by the probabilities)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incoming-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[872]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -7.08377979,  -0.38828262, -53.7297659 ,   6.83221631,\n",
       "        -2.67213445])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam\n",
    "print(np.where(prob_token_overall==0)[0]) # index which contains the value 0 (causing problems to apply log)\n",
    "prob_token_overall[872] = 0.00000000001 # make it nonzero\n",
    "joint_log_spam = X_test.dot(np.log(prob_token_spam) - np.log(prob_token_overall)) + np.log(PRIOR_PROB_SPAM)\n",
    "joint_log_spam[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "massive-coverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.66619644,  -3.01136782,  -5.48219505, -22.98376209,\n",
       "        -4.63684008])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ham > P(Ham) = 1 - P(Spam)\n",
    "joint_log_ham = X_test.dot(np.log(prob_token_ham) - np.log(prob_token_overall)) + np.log(1 - PRIOR_PROB_SPAM)\n",
    "joint_log_ham[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-hours",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
