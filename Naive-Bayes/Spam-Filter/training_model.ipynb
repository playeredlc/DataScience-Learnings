{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# local package\n",
    "from full_matrix import gen_full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accompanied-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 2500\n",
    "\n",
    "TRAIN_DATA_FILE = 'spam-data/train-data.txt'\n",
    "TEST_DATA_FILE = 'spam-data/test-data.txt'\n",
    "\n",
    "TOKEN_SPAM_PROB_FILE = 'spam-data/token-spam-prob.txt'\n",
    "TOKEN_HAM_PROB_FILE = 'spam-data/token-ham-prob.txt'\n",
    "TOKEN_OVERALL_PROB_FILE = 'spam-data/token-overall-prob.txt'\n",
    "\n",
    "TEST_FEATURE_MATRIX = 'spam-data/test-features.txt'\n",
    "TEST_TARGET_FILE = 'spam-data/test-target.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-bouquet",
   "metadata": {},
   "source": [
    "# *Load the data generated from the pre_proccess stage*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "planned-mortality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.52 s, sys: 73.8 ms, total: 4.59 s\n",
      "Wall time: 4.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sparse_train_data = np.loadtxt(TRAIN_DATA_FILE, delimiter=' ', dtype=int)\n",
    "sparse_test_data = np.loadtxt(TEST_DATA_FILE, delimiter=' ', dtype=int)\n",
    "\n",
    "# CPU times: user 4.44 s, sys: 60.3 ms, total: 4.5 s\n",
    "# Wall time: 4.51 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuffed-tourism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      " [[0 1 1 1]\n",
      " [0 5 1 1]\n",
      " [0 6 1 1]] \n",
      "---\n",
      " [[5795 2144    0    1]\n",
      " [5795 2267    0    1]\n",
      " [5795 2303    0    1]]\n",
      "test: \n",
      " [[8 0 1 2]\n",
      " [8 2 1 1]\n",
      " [8 3 1 1]] \n",
      "---\n",
      " [[5793 1872    0    1]\n",
      " [5793 1964    0    1]\n",
      " [5793 2310    0    1]]\n"
     ]
    }
   ],
   "source": [
    "# quick check the data loaded\n",
    "print('train:\\n', sparse_train_data[:3], '\\n---\\n',sparse_train_data[-3:])\n",
    "print('test: \\n', sparse_test_data[:3], '\\n---\\n', sparse_test_data[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "isolated-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in TRAINING file:  264056\n",
      "Emails in TRAINING file:  4016\n",
      "\n",
      "\n",
      "Rows in TESTING file:  112088\n",
      "Emails in TESTING file:  1721\n"
     ]
    }
   ],
   "source": [
    "print('Rows in TRAINING file: ', sparse_train_data.shape[0])\n",
    "print('Emails in TRAINING file: ', np.unique(sparse_train_data[:, 0]).size)\n",
    "print('\\n')\n",
    "print('Rows in TESTING file: ', sparse_test_data.shape[0])\n",
    "print('Emails in TESTING file: ', np.unique(sparse_test_data[:, 0]).size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-confidentiality",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-timothy",
   "metadata": {},
   "source": [
    "## *Generate the full matrix from the sparse_train_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alert-conspiracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 136 ms, total: 14.3 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_train_data = gen_full_matrix(sparse_train_data, VOCAB_SIZE)\n",
    "\n",
    "# CPU times: user 22.6 s, sys: 315 ms, total: 22.9 s\n",
    "# Wall time: 23.1 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conventional-dayton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4016 rows × 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CATEGORY  0  1  2  3  4  5  6  7  8  ...  2490  2491  2492  2493  \\\n",
       "DOC_ID                                       ...                           \n",
       "0              1  0  1  0  0  0  1  1  0  0  ...     0     0     0     0   \n",
       "1              1  1  2  0  2  2  0  1  0  1  ...     0     0     0     0   \n",
       "2              1  0  0  0  0  0  0  0  2  0  ...     0     0     0     0   \n",
       "3              1  1  0  0  2  1  2  2  4  0  ...     0     0     0     0   \n",
       "4              1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0   \n",
       "...          ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   \n",
       "5789           0  2  2  1  0  0  0  1  0  0  ...     0     0     0     0   \n",
       "5790           0  6  0  3  3  2  3  0  0  0  ...     0     0     0     0   \n",
       "5791           0  2  1  1  0  0  1  1  0  0  ...     0     0     0     0   \n",
       "5794           0  4  0  1  0  0  0  3  0  1  ...     0     0     0     0   \n",
       "5795           0  5  1  2  2  0  2  1  0  1  ...     0     0     0     0   \n",
       "\n",
       "        2494  2495  2496  2497  2498  2499  \n",
       "DOC_ID                                      \n",
       "0          0     0     0     0     0     0  \n",
       "1          0     0     0     0     0     0  \n",
       "2          0     0     0     0     0     0  \n",
       "3          0     0     0     0     0     0  \n",
       "4          0     0     0     0     0     0  \n",
       "...      ...   ...   ...   ...   ...   ...  \n",
       "5789       0     0     0     0     0     0  \n",
       "5790       0     0     0     0     0     0  \n",
       "5791       0     0     0     0     0     0  \n",
       "5794       0     0     0     0     0     0  \n",
       "5795       0     0     0     0     0     0  \n",
       "\n",
       "[4016 rows x 2501 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-express",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-packing",
   "metadata": {},
   "source": [
    "### *Probability of being spam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accurate-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 4016\n",
      "Total of spam: 1251\n",
      "Probability of being Spam: 31.15 %\n"
     ]
    }
   ],
   "source": [
    "# probability of being Spam\n",
    "\n",
    "print('Total documents:', full_train_data.CATEGORY.size)\n",
    "print('Total of spam:', full_train_data.CATEGORY.sum())\n",
    "\n",
    "prob_spam = full_train_data.CATEGORY.sum() / full_train_data.CATEGORY.size\n",
    "print('Probability of being Spam:', '%.2f' % (prob_spam*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-diagram",
   "metadata": {},
   "source": [
    "### *Number of tokens*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "robust-service",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOC_ID\n",
       "0       134\n",
       "1       116\n",
       "2        34\n",
       "3       113\n",
       "4        34\n",
       "       ... \n",
       "5789     88\n",
       "5790     92\n",
       "5791     72\n",
       "5794    113\n",
       "5795    124\n",
       "Length: 4016, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of tokens\n",
    "full_train_features = full_train_data.loc[:, full_train_data.columns != 'CATEGORY'] # excluding category column\n",
    "\n",
    "email_lenghts = full_train_features.sum(axis=1) # for each row sum up all columns\n",
    "email_lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excited-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 439447\n"
     ]
    }
   ],
   "source": [
    "total_tokens = email_lenghts.sum()\n",
    "print('Total number of tokens:', total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threatened-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in SPAM emails: 191434\n"
     ]
    }
   ],
   "source": [
    "# total number of tokens in SPAM emails\n",
    "spam_lengths = email_lenghts[full_train_data.CATEGORY == 1]\n",
    "total_spam_tokens = spam_lengths.sum()\n",
    "print('Total number of tokens in SPAM emails:', total_spam_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "identified-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in HAM emails: 248013\n"
     ]
    }
   ],
   "source": [
    "# total number of tokens in HAM emails\n",
    "ham_lenghts = email_lenghts[full_train_data.CATEGORY == 0]\n",
    "total_ham_tokens = ham_lenghts.sum()\n",
    "print('Total number of tokens in HAM emails:', total_ham_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "general-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up each token occurence in spam/ham\n",
    "spam_train_features = full_train_features.loc[full_train_data.CATEGORY == 1]\n",
    "summed_spam = spam_train_features.sum(axis=0) + 1 # LaPlace smoothing\n",
    "\n",
    "ham_train_features = full_train_features.loc[full_train_data.CATEGORY == 0]\n",
    "summed_ham = ham_train_features.sum(axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "theoretical-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2307\n",
       "1       1011\n",
       "2       1363\n",
       "3       2109\n",
       "4       1326\n",
       "        ... \n",
       "2495       5\n",
       "2496       6\n",
       "2497       2\n",
       "2498      19\n",
       "2499       3\n",
       "Length: 2500, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rapid-canvas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5145\n",
       "1       2427\n",
       "2       2022\n",
       "3        869\n",
       "4       1624\n",
       "        ... \n",
       "2495      27\n",
       "2496      21\n",
       "2497      31\n",
       "2498      19\n",
       "2499      31\n",
       "Length: 2500, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-waters",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-panama",
   "metadata": {},
   "source": [
    "# *Calculate the probability that a token occurs given the email is SPAM / HAM, and overall probability*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-watershed",
   "metadata": {},
   "source": [
    "## *P(Token | Spam)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "random-sunrise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check sum: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.011896\n",
       "1       0.005213\n",
       "2       0.007028\n",
       "3       0.010875\n",
       "4       0.006837\n",
       "          ...   \n",
       "2495    0.000026\n",
       "2496    0.000031\n",
       "2497    0.000010\n",
       "2498    0.000098\n",
       "2499    0.000015\n",
       "Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_token_spam = summed_spam / (total_spam_tokens + VOCAB_SIZE) # LaPlace smoothing balance\n",
    "print('Check sum:', prob_token_spam.sum())\n",
    "prob_token_spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-stadium",
   "metadata": {},
   "source": [
    "## *P(Token | Ham)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "shaped-hunger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check sum: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.020538\n",
       "1       0.009688\n",
       "2       0.008071\n",
       "3       0.003469\n",
       "4       0.006483\n",
       "          ...   \n",
       "2495    0.000108\n",
       "2496    0.000084\n",
       "2497    0.000124\n",
       "2498    0.000076\n",
       "2499    0.000124\n",
       "Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_token_ham = summed_ham / (total_ham_tokens + VOCAB_SIZE)  # LaPlace smoothing balance\n",
    "print('Check sum:', prob_token_ham.sum())\n",
    "prob_token_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-zoning",
   "metadata": {},
   "source": [
    "## *P(Token)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "equipped-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check sum: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.016953\n",
       "1       0.007819\n",
       "2       0.007698\n",
       "3       0.006772\n",
       "4       0.006708\n",
       "          ...   \n",
       "2495    0.000068\n",
       "2496    0.000057\n",
       "2497    0.000071\n",
       "2498    0.000082\n",
       "2499    0.000073\n",
       "Length: 2500, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall probability that a token occurs (regardless of spam or nonspam)\n",
    "prob_token_overall = full_train_features.sum(axis=0) / total_tokens\n",
    "print('Check sum:', prob_token_overall.sum())\n",
    "prob_token_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-playback",
   "metadata": {},
   "source": [
    "# *Export the trained model (probabilities) as txt files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "golden-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TOKEN_SPAM_PROB_FILE, prob_token_spam)\n",
    "np.savetxt(TOKEN_HAM_PROB_FILE, prob_token_ham)\n",
    "np.savetxt(TOKEN_OVERALL_PROB_FILE, prob_token_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-construction",
   "metadata": {},
   "source": [
    "---\n",
    "# *Prepare test data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "democratic-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.97 s, sys: 39.6 ms, total: 7.01 s\n",
      "Wall time: 7.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_test_data = gen_full_matrix(sparse_test_data, VOCAB_SIZE)\n",
    "\n",
    "# CPU times: user 6.97 s, sys: 39.6 ms, total: 7.01 s\n",
    "# Wall time: 7.02 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consecutive-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = full_test_data.loc[:, full_test_data.columns != 'CATEGORY']\n",
    "y_test = full_test_data.CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "golden-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "np.savetxt(TEST_FEATURE_MATRIX, X_test)\n",
    "np.savetxt(TEST_TARGET_FILE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-professor",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
